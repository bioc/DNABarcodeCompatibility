---
title: "Simulations"
author: "Raphael"
date: "14/6/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
SCRIPT_DIR=file.path(Sys.getenv("HOME"),"DNABarcodeCompatibility")
```

DNABarcodeCompatibility works in 2 steps:

* Step1: find compatible combinations of barcodes

* Step2: optimize the set of compatible barcodes to minimize redundancy between barcodes

TODO:

* histogram des barcodes pour les deux chimies parmi les comb compatibles
* même hist arpès optimization.
* simulation avec jeux compatibles pour calculer la proba d'obtenir solution optimale


# Simulations relative to Step1 of the workflow

* Step1: find compatible combinations of barcodes


## Define parameters for the simulations
```{r echo = FALSE}

R=2
L = c(12,18)#,24,30,36,42,48)
N = 2:5
C = c(1,2,4)

print(paste("Number of conditions:",R*length(L)*length(N)*length(C)))

```

## Run simulations
```{r echo = FALSE}

# Initialize output file1 (barcode occurrences)
write.table(data.frame(barcodeID=character(0), occurrence=integer(0), mplex_level=integer(0), barcode_number=integer(0), chemistry=integer(0)),
 outputfile1 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Initialize output file2 (execution time)
write.table(data.frame(time=numeric(0), nb_total_combinations=integer(0), nb_comp_combinations=integer(0), mplex_level=integer(0), barcode_number=integer(0), chemistry=integer(0)),
 outputfile2 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Detect CPU number
nb_cpu=parallel::detectCores()

# Run simulation using GNU parallel (Windows users need cygwin + Gnu parallel; MacOs: brew install parallel; Linux: apt-get install parallel)
system.time({
  system(paste0("parallel -j",nb_cpu," Rscript ",SCRIPT_DIR,"/vignettes/sim_get_all_combinations.R {1} {2} {3} {4} {5} ::: ",paste(rep(N,R), collapse=" ")," ::: ",paste(L, collapse=" ")," ::: ",paste(C, collapse=" "), " ::: ", paste(outputfile1, collapse=""), " ::: ", paste(outputfile2, collapse="")))
})

# Import results
barcodeFreq <- read.table(file=outputfile1, header = T, sep = " ", stringsAsFactors = FALSE)
save(barcodeFreq, file ="barcodeFreq")
# barcodeFreq <- local(get(load("barcodeFreq")))
results <- read.table(file=outputfile2, header = T, sep = " ", stringsAsFactors = FALSE)
save(results, file = "results")
# results <- local(get(load("results")))

```




### Plot execution time = f(barcode set size)
```{r echo = FALSE}
library("dplyr")
library("ggplot2")
head(results)
results %>% group_by(mplex_level, barcode_number, chemistry) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_total_combinations=nb_total_combinations[1], nb_comp_combinations.avg=mean(nb_comp_combinations)) %>%
  ungroup() %>% mutate(mplex_level=as.factor(mplex_level),
                       channel=paste0(chemistry, "-channels")) %>%
ggplot(aes( x = barcode_number, y = time.avg, color = mplex_level))+
  geom_point()+
  geom_errorbar(aes(ymin=(time.avg-time.sd), ymax=(time.avg+time.sd)),
                size=0.3,color="black") +
  scale_x_log10(breaks=L) +
  scale_y_log10(breaks = c(1, 5, 10,30,90,200))+
  geom_hline(yintercept=30, linetype="dashed", color = "red")+
  geom_hline(yintercept=10, linetype="dashed", color = "red")+
  geom_smooth(method = "lm", se = FALSE)+
  facet_grid(~channel) +
  ggtitle(paste("Execution time by chemistry (log-log scale) for", R, "replicates of each simulation"))+
  xlab("Barcode set size")+
  ylab("Execution time [s]")


```


### Plot nb_comp_combinations.avg = f(nb_total_combinations)
```{r echo = FALSE}
results %>% group_by(mplex_level, barcode_number, chemistry) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_total_combinations=nb_total_combinations[1], nb_comp_combinations.avg=mean(nb_comp_combinations)) %>%
  ungroup() %>% mutate(mplex_level=as.factor(mplex_level),
                       channel=paste0(chemistry, "-channels")) %>%
ggplot(aes( x = nb_total_combinations, y = nb_comp_combinations.avg, color = mplex_level))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)+
  # geom_smooth(method = "lm", formula =  y ~ poly(x, 2), se = FALSE) +
  facet_grid(~channel) +
  ggtitle(paste("XX by chemistry (log-log scale) for", R, "replicates of each simulation"))+
  xlab("nb_total_combinations")+
  ylab("nb_comp_combinations.avg")


```


### Plot proportion of compatible barcodes from an exhaustive search
```{r echo = FALSE}
results %>% group_by(mplex_level, barcode_number, chemistry) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_total_combinations=nb_total_combinations[1], nb_comp_combinations.avg=mean(nb_comp_combinations), nb_comp_combinations.sd=sd(nb_comp_combinations)) %>%
  ungroup() %>% mutate(mplex_level=as.factor(mplex_level),
                       channel=paste0(chemistry, "-channels"),
                       comp_comb_prop.avg= nb_comp_combinations.avg/nb_total_combinations,
                       comp_comb_prop.sd= nb_comp_combinations.sd/nb_total_combinations,
                       condition=paste(mplex_level,stringr::str_pad(barcode_number, 2, pad = "0"), sep = "-")) %>%
  ggplot(aes(x=condition,y=comp_comb_prop.avg, fill = mplex_level))+
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=(comp_comb_prop.avg-comp_comb_prop.sd), ymax=(comp_comb_prop.avg+comp_comb_prop.sd)),
                size=0.3,color="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1))+
  facet_grid(~channel) +
  scale_y_continuous(breaks=seq(0, 1, 0.2), limit=c(0, 1)) +
  xlab("Condition: mplex_level-barcode_number")+
  ylab("Proportion of compatible barcodes")+
ggtitle(paste("Proportion of compatible barcodes for", R, "replicates of each simulation"))


```

### Plot barcodes frequency amongst compatible barcodes from all simulations
```{r echo = FALSE}
barcodeFreq %>% filter(chemistry >1) %>%
  group_by(mplex_level, chemistry) %>%
  mutate(sum_barcodes=sum(occurrence)) %>%
  group_by(barcodeID, mplex_level, chemistry) %>%
  summarise(freq=sum(occurrence)/sum_barcodes[1]) %>% ungroup() %>%
  mutate(channel=paste0(chemistry, "-channels"),
         mplex_level=as.factor(mplex_level)) %>%
  ggplot(aes(x=barcodeID,y=freq, fill=mplex_level))+
  geom_histogram(stat = "identity")+
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
  facet_grid(mplex_level~channel) +
  xlab("BarcodeID")+
  ylab("Barcodes frequency")+
ggtitle(paste("Barcodes frequency amongst compatible barcodes from all simulations"))
```


# Simulations relative to Step2 of the workflow

* Step2: optimize the set of compatible barcodes to minimize redundancy between barcodes

The goal is to estimate the probabiity to get an optimal solution with the optimizer and to test how the optimizer improves the solution compared with a random pick

## Define parameters for the simulations

From simulations in step1, we know that a threshold of 1000 compatible barcode combinations is reached for mplex_level >= 4 , barcode set >= 18, for all chemistries.

```{r echo = FALSE}

R=20
L = c(18)
N = 4
C = c(4)
thrs_size_comb=c(60)#, 100, 300, 500, 750, 1000)
nb_lane=c(4)

print(paste("Number of conditions:",R*length(L)*length(N)*length(C)*length(thrs_size_comb)*length(nb_lane)))

```

## Run simulations
```{r echo = FALSE}

# Generate 2 large sets of compatible combinations
index <- dplyr::sample_n(DNABarcodeCompatibility::IlluminaIndexes, nrow(DNABarcodeCompatibility::IlluminaIndexes), replace = FALSE)

# combination_m_2ch <- DNABarcodeCompatibility::get_all_combinations(index_df = index[1:L,], mplex_level = N, chemistry = 2)


combination_m_4ch <- DNABarcodeCompatibility::get_all_combinations(index_df = index[1:L,], mplex_level = N, chemistry = 4)
inputfile <- tempfile()
save(combination_m_4ch, file=inputfile)


# Initialize output file1 (calcul of proba to get an optimal solution)
write.table(data.frame(time=numeric(0), nb_comp_combinations=integer(0), rep_number=integer(0), barcode_number=integer(0), thrs_size_comb=integer(0), Smax=numeric(0), S=numeric(0), chemistry=integer(0), nb_lane=integer(0)),
            outputfile1 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Detect CPU number
nb_cpu=parallel::detectCores()

# Run simulation using GNU parallel (Windows users need cygwin + Gnu parallel; MacOs: brew install parallel; Linux: apt-get install parallel)
system.time({
  system(paste0("parallel -j",nb_cpu," Rscript ",SCRIPT_DIR,"/vignettes/sim_optimize_combinations.R {1} {2} {3} {4} {5} {6} {7} {8} ::: ",paste(1:R, collapse=" ")," ::: ",paste(thrs_size_comb, collapse=" ")," ::: ",paste(inputfile, collapse=""), " ::: ", paste(nb_lane, collapse=""), " ::: ", paste(L, collapse=""), " ::: ", paste(4, collapse=""), " ::: ", paste(outputfile1, collapse="")))
})

# Import results
probaSmax <- read.table(file=outputfile1, header = T, sep = " ", stringsAsFactors = FALSE)

save(probaSmax, file ="probaSmax")
# probaSmax <- local(get(load("probaSmax")))

# results <- read.table(file=outputfile2, header = T, sep = " ", stringsAsFactors = FALSE)

```
