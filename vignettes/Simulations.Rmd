---
title: "Simulations"
author: "Tr√©beau, Boutet de Monvel, et al., Etournay."
date: "`r format(Sys.Date(), '%m/%d/%Y')`"
output:
  html_document:
    fig_caption: yes
    keep_md: yes
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width=120)
# options(digits=3)

SCRIPT_DIR=file.path(Sys.getenv("HOME"),"DNABarcodeCompatibility/vignettes/")
if (!file.exists(SCRIPT_DIR)) stop("Script directory not properly set up !")
library("dplyr")
library("ggplot2")
```

# Introduction

DNABarcodeCompatibility works in 2 steps:

* Step1: find compatible combinations of barcodes

* Step2: optimize the set of compatible barcodes to minimize redundancy between barcodes


# Simulations relative to Step1 of the workflow: find compatible combinations of barcodes

To find compatible combinations of DNA barcodes, one approach is to generate all possible combinations of DNA barcodes and perform an exhaustive search of compatible combinations.
However, the total number of combinations may become prohibitively large for large barcode sets and large multiplexing numbers. Thus, an exhaustive search of compatible combinations among all possible combinations may not be possible. An alternive strategy is to choose a fixed number of randomly selected combinations for finding compatible combinations. To determine the conditions for which a random search is preferable over an exhaustive search, we will consider the execution time of the program as a critical parameter. 


## Set parameters for the simulations

The execution time of the program depends on the size of the barcode dataset, the multiplex level and the Illumina chemistry. We therefore test different values of these parameters to vizualise how they influence the execution time.

```{r echo = FALSE, cache=F}

R=10
L = c(12,18,24,30,36,42,48)
N = 2:5
C = c(1,2,4)

# R=2
# L = c(12,18)
# N = 2:5
# C = c(2,4)

print("CONDITIONS:")
print("Barcode set size:")
L
print("Multiplex levels:")
N 
print("Chemistry:")
C
print("Number of simulations per condition:")
R
print(paste("Total number of simulations:",R*length(L)*length(N)*length(C)))

```

## Run simulations for exhaustive searches
```{r echo = FALSE, cache=F}

# Initialize output file1 (barcode occurrences)
write.table(data.frame(barcodeID=character(0), occurrence=integer(0), rep_number=integer(0), mplex_level=integer(0), barcode_number=integer(0), chemistry=integer(0)),
 outputfile1 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Initialize output file2 (execution time)
write.table(data.frame(rep_number=integer(0), time=numeric(0), nb_total_combinations=integer(0), nb_comp_combinations=integer(0), mplex_level=integer(0), barcode_number=integer(0), chemistry=integer(0)),
 outputfile2 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Detect CPU number
nb_cpu=parallel::detectCores()

if (F) {
  # Run simulation using GNU parallel (Windows users need cygwin + Gnu parallel; MacOs: brew install parallel; Linux: apt-get install parallel)
  print(paste("Running", R*length(L)*length(N)*length(C) ,"simulations..."))
  system.time({
    system(paste0("parallel -j",nb_cpu," Rscript ",SCRIPT_DIR,"sim_get_all_combinations.R {1} {2} {3} {4} {5} {6} ::: ",paste(1:R, collapse=" ")," ::: ",paste(N, collapse=" ")," ::: ",paste(L, collapse=" ")," ::: ",paste(C, collapse=" "), " ::: ", paste(outputfile1, collapse=""), " ::: ", paste(outputfile2, collapse="")))
  })
  
  barcodeFreq <- read.table(file=outputfile1, header = T, sep = " ", stringsAsFactors = FALSE)
  save(barcodeFreq, file = paste0(SCRIPT_DIR,"barcodeFreq"))

  results <- read.table(file=outputfile2, header = T, sep = " ", stringsAsFactors = FALSE)
  save(results, file = paste0(SCRIPT_DIR,"results"))
}


# Import results
barcodeFreq <- local(get(load(paste0(SCRIPT_DIR,"barcodeFreq"))))
results <- local(get(load(paste0(SCRIPT_DIR,"results"))))

```



### Execution time of an exhaustive search as a function of the total number of combinations

The execution time of an exhaustive search increases as a power of the total number of combinations. It is slighty faster for the 4-channel chemistry. 
For the ease of use, we fix at around 2 seconds the maximum time of execution. On a standard computer, this corresponds to an exhaustive search among about 2000 combinations for the 4-channel chemistry.
Above 2000 combinations, the program will then perform a search of compatible barcodes from a randomly generated set of barcode combinations.


```{r echo = FALSE, fig.width=11}
results %>% group_by(mplex_level, barcode_number, chemistry) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_total_combinations=nb_total_combinations[1], nb_comp_combinations.avg=mean(nb_comp_combinations)) %>%
  ungroup() %>% mutate(mplex_level=as.factor(mplex_level),
                       channel=paste0(chemistry, "-channel")) %>%
ggplot(aes( x = nb_total_combinations, y = time.avg))+
  geom_point()+
  geom_errorbar(aes(ymin=(time.avg-time.sd), ymax=(time.avg+time.sd)),
                size=0.7,color="black") +
  scale_x_log10(breaks= c(10, 10^2, 10^3, 10^4, 10^5, 10^6, 10^7), labels=scales::scientific) +
  scale_y_log10(breaks = c(1, 2, 5, 10,30,90,200, 1200, 3600, 5000))+
  geom_hline(yintercept=30, linetype="dashed", color = "red")+
  geom_hline(yintercept=10, linetype="dashed", color = "red")+
  geom_hline(yintercept=2, linetype="dashed", color = "red")+
  geom_smooth(method = "lm", se = FALSE)+
  facet_grid(~channel) +
  ggtitle(paste("Execution time for increasing number of combinations ( average over", R,"simulations )"))+
  xlab("Total number of combinations")+
  ylab("Execution time [s]")
```


### Execution time of an exhaustive search as a function of the barcode-set size

The total number of combinations can be expressed as a binomial coefficient that is indexed by n barcodes in the barcode dataset and a mutliplex level k, where both n and k are positive integers.
We now plot the execution time as function of the barcode-set size for various multiplex levels. This reveals that the execution time is less than 2 seconds for a multiplex level of 2 with the 48-barcode Illumina small RNA TruSep kit.
Therefore, in these conditions, the program will perform an exhaustive search of compatible combinations for a multiplex level of 2. For a multiplex level higher than 4, the program will instead perform a search of compatible barcodes from a randomly generated set of barcode combinations.


```{r echo = FALSE, fig.width=11}
results %>% group_by(mplex_level, barcode_number, chemistry) %>%
  filter(chemistry > 1) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_total_combinations=nb_total_combinations[1], nb_comp_combinations.avg=mean(nb_comp_combinations)) %>%
  ungroup() %>% mutate(mplex_level=as.factor(mplex_level),
                       channel=paste0(chemistry, "-channel")) %>%
ggplot(aes( x = barcode_number, y = time.avg, color = mplex_level))+
  geom_point()+
  geom_errorbar(aes(ymin=(time.avg-time.sd), ymax=(time.avg+time.sd)),
                size=0.3,color="black") +
  scale_x_log10(breaks=L) +
  scale_y_log10(breaks = c(1, 2,5, 10,30,90,200,1000,5000))+
  geom_hline(yintercept=30, linetype="dashed", color = "red")+
  geom_hline(yintercept=10, linetype="dashed", color = "red")+
  geom_hline(yintercept=2, linetype="dashed", color = "red")+
  geom_smooth(method = "lm", se = FALSE)+
  facet_grid(~channel) +
  ggtitle(paste("Execution time by multiplex levels ( average over", R,"simulations )"))+
  xlab("Barcode set size")+
  ylab("Execution time [s]")


```


### Probability to find compatible barcodes in the complete ensemble of combinations

* The probability to find compatible barcodes is more variable for smaller barcode sets 

```{r echo = FALSE, warning=FALSE, fig.width=11}
results %>% group_by(mplex_level, barcode_number, chemistry) %>%
  filter(chemistry > 0) %>% filter(mplex_level==3) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_total_combinations=nb_total_combinations[1], nb_comp_combinations.avg=mean(nb_comp_combinations), nb_comp_combinations.sd=sd(nb_comp_combinations)) %>%
  ungroup() %>% mutate(mplex_level=as.factor(mplex_level),
                       channel=paste0(chemistry, "-channel"),
                       comp_comb_prop.avg= nb_comp_combinations.avg/nb_total_combinations,
                       comp_comb_prop.sd= nb_comp_combinations.sd/nb_total_combinations,
                       barcode_number=as.factor(barcode_number)) %>%
  ggplot(aes(x=barcode_number,y=comp_comb_prop.avg, fill = mplex_level))+
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=(comp_comb_prop.avg-comp_comb_prop.sd), ymax=(comp_comb_prop.avg+comp_comb_prop.sd)),
                size=0.3,color="black") +
  theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1))+
  facet_grid(~channel) +
  scale_fill_manual(values = c("darkgrey")) + 
  # scale_y_continuous(breaks=seq(0, 1, 0.2), limit=c(0, 1)) +
  xlab("Barcode set size")+
  ylab("Proportion of compatible barcodes")+
ggtitle(paste("Average proportion of compatible barcodes ( average over", R,"simulations )"))


```


* The probability to find compatible barcodes increases with the multiplex level


```{r echo = FALSE, warning=FALSE, fig.width=11}
results %>% group_by(mplex_level, barcode_number, chemistry) %>%
  filter(chemistry > 0) %>%
  summarise(nb_total_combinations=nb_total_combinations[1], nb_comp_combinations=mean(nb_comp_combinations), comp_comb_prop=nb_comp_combinations/nb_total_combinations) %>%
  group_by(mplex_level, chemistry) %>% 
  summarize(comp_comb_prop.avg= mean(comp_comb_prop),
            comp_comb_prop.sd= sd(comp_comb_prop)) %>% ungroup() %>%
  mutate(mplex_level=as.factor(mplex_level),
         channel=paste0(chemistry, "-channel")) %>%
  ggplot(aes(x=mplex_level,y=comp_comb_prop.avg, fill = mplex_level))+
  geom_histogram(stat = "identity")+
  geom_errorbar(aes(ymin=(comp_comb_prop.avg-comp_comb_prop.sd), ymax=(comp_comb_prop.avg+comp_comb_prop.sd)),
  size=0.3,color="black") +
  # theme(axis.text.x=element_text(angle=45, hjust=1, vjust=1))+
  facet_grid(~channel) +
  scale_y_continuous(breaks=seq(0, 1, 0.2), limit=c(0, 1)) +
  xlab("Multiplex level")+
  ylab("Proportion of compatible barcodes")+
  ggtitle(paste("Probability to find compatible barcodes  ( average over", R,"simulations and barcode-set size )"))


```

### Compatible barcode combinations: average barcode frequencies among input barcode sets

The distribution of barcodes used to form compatible combinations may be highly heterogeneous at low multiplex levels. 
We plot the distribution of barcodes averaged over the different barcode sets, for distinct chemistries and multiplex levels.
Despite the averaging the distibutions over different barcode sets of different sizes, the variability of barcode frequencies is still visible.

* 4-channel chemistry

```{r echo = FALSE, warning=FALSE, fig.width=11}
if (4 %in% barcodeFreq$chemistry) {
  barcodeFreq %>% filter(chemistry == 4) %>% 
    group_by(mplex_level, chemistry, barcode_number) %>%
    mutate(sum_barcodes=sum(occurrence)) %>%
    group_by(barcodeID, mplex_level, chemistry, barcode_number) %>%
    summarise(freq=sum(occurrence)/sum_barcodes[1]) %>% 
    group_by(barcodeID, mplex_level, chemistry) %>%
    summarize(freq.avg=mean(freq), freq.sd=sd(freq)) %>% ungroup() %>%
    mutate(channel=paste0(chemistry, "-channel"),
           mplex_level=as.factor(mplex_level)) %>%
    ggplot(aes(x=barcodeID,y=freq.avg, fill=mplex_level))+
    geom_histogram(stat = "identity")+
    geom_errorbar(aes(ymin=(freq.avg-freq.sd), ymax=(freq.avg+freq.sd)),
                  size=0.7,color="black") +
    theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
    scale_y_continuous(breaks=seq(0, 0.18, 0.04), limit=c(0, 0.18)) +
    facet_grid(mplex_level~channel) +
    xlab("BarcodeID")+
    ylab("Barcodes frequency")+
    ggtitle(paste("Barcode frequency averaged over barcode sets (4-channel chemistry)"))
}
```

* 2-channel chemistry

```{r echo = FALSE, warning=FALSE, fig.width=11}
if (2 %in% barcodeFreq$chemistry) {
  barcodeFreq %>% filter(chemistry == 2) %>% 
    group_by(mplex_level, chemistry, barcode_number) %>%
    mutate(sum_barcodes=sum(occurrence)) %>%
    group_by(barcodeID, mplex_level, chemistry, barcode_number) %>%
    summarise(freq=sum(occurrence)/sum_barcodes[1]) %>% 
    group_by(barcodeID, mplex_level, chemistry) %>%
    summarize(freq.avg=mean(freq), freq.sd=sd(freq)) %>% ungroup() %>%
    mutate(channel=paste0(chemistry, "-channel"),
           mplex_level=as.factor(mplex_level)) %>%
    ggplot(aes(x=barcodeID,y=freq.avg, fill=mplex_level))+
    geom_histogram(stat = "identity")+
    geom_errorbar(aes(ymin=(freq.avg-freq.sd), ymax=(freq.avg+freq.sd)),
                  size=0.7,color="black") +
    theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
    scale_y_continuous(breaks=seq(0, 0.18, 0.04), limit=c(0, 0.18)) +
    facet_grid(mplex_level~channel) +
    xlab("BarcodeID")+
    ylab("Barcodes frequency")+
    ggtitle(paste("Barcode frequency averaged over barcode sets (2-channel chemistry)"))
}
```

* 1-channel chemistry

```{r echo = FALSE, warning=FALSE, fig.width=11}
if (1 %in% barcodeFreq$chemistry) {
  barcodeFreq %>% filter(chemistry == 1) %>% 
    group_by(mplex_level, chemistry, barcode_number) %>%
    mutate(sum_barcodes=sum(occurrence)) %>%
    group_by(barcodeID, mplex_level, chemistry, barcode_number) %>%
    summarise(freq=sum(occurrence)/sum_barcodes[1]) %>% 
    group_by(barcodeID, mplex_level, chemistry) %>%
    summarize(freq.avg=mean(freq), freq.sd=sd(freq)) %>% ungroup() %>%
    mutate(channel=paste0(chemistry, "-channel"),
           mplex_level=as.factor(mplex_level)) %>%
    ggplot(aes(x=barcodeID,y=freq.avg, fill=mplex_level))+
    geom_histogram(stat = "identity")+
    geom_errorbar(aes(ymin=(freq.avg-freq.sd), ymax=(freq.avg+freq.sd)),
                  size=0.7,color="black") +
    theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
    scale_y_continuous(breaks=seq(0, 0.18, 0.04), limit=c(0, 0.18)) +
    facet_grid(mplex_level~channel) +
    xlab("BarcodeID")+
    ylab("Barcodes frequency")+
    ggtitle(paste("Barcode frequency averaged over barcode sets (1-channel chemistry)"))
}

```

### Compatible barcode combinations: single examples

Individual barcode sets of 12 barcodes were randomly generated from the four Illumina TruSeq small RNA kits comprising 48 barcodes in total. We clearly see that barcode occurences are very heterogeneous even for multiplex levels of 4 or 5. Therefore, consumable usage may strongly be biased among preparation kits.

* 4-channel chemistry, multiplex level 4, barcode-set size 12

```{r echo = FALSE, warning=FALSE, fig.width=8}
chem=4
mpl=4
bcnb=12
repnb=3

nb_comp_combinations <- (results %>% filter(chemistry == chem) %>% 
   filter(mplex_level==mpl) %>%
   filter(barcode_number==bcnb) %>%
   filter(rep_number==repnb))$nb_comp_combinations

barcodeFreq %>% filter(chemistry == chem) %>% 
  filter(mplex_level==mpl) %>%
  filter(barcode_number==bcnb) %>%
  filter(rep_number==repnb) %>%
  mutate(channel=paste0(chemistry, "-channel"),
         mplex_level=paste("mutiplex level",mplex_level)) %>%
  ggplot(aes(x=barcodeID,y=occurrence, fill=mplex_level))+
  geom_histogram(stat = "identity", fill= "darkgrey")+
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
  facet_grid(mplex_level~channel) +
  xlab("BarcodeID")+
  ylab("Barcode occurrences")+
ggtitle(paste("Barcode occurences among",nb_comp_combinations,"compatible barcode combinations (",chem,"- channel )"))
```

* 4-channel chemistry, multiplex level 5, barcode-set size 12

```{r echo = FALSE, warning=FALSE, fig.width=8}
chem=4
mpl=5
bcnb=12
repnb=3

nb_comp_combinations <- (results %>% filter(chemistry == chem) %>% 
   filter(mplex_level==mpl) %>%
   filter(barcode_number==bcnb) %>%
   filter(rep_number==repnb))$nb_comp_combinations

barcodeFreq %>% filter(chemistry == chem) %>% 
  filter(mplex_level==mpl) %>%
  filter(barcode_number==bcnb) %>%
  filter(rep_number==repnb) %>%
  mutate(channel=paste0(chemistry, "-channel"),
         mplex_level=paste("mutiplex level",mplex_level)) %>%
  ggplot(aes(x=barcodeID,y=occurrence, fill=mplex_level))+
  geom_histogram(stat = "identity", fill= "darkgrey")+
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
  facet_grid(mplex_level~channel) +
  xlab("BarcodeID")+
  ylab("Barcode occurences")+
ggtitle(paste("Barcode occurences among",nb_comp_combinations,"compatible barcode combinations (",chem,"- channel )"))
```


* 2-channel chemistry, multiplex level 4, barcode-set size 12

```{r echo = FALSE, warning=FALSE, fig.width=8}
chem=2
mpl=4
bcnb=12
repnb=3

nb_comp_combinations <- (results %>% filter(chemistry == chem) %>% 
   filter(mplex_level==mpl) %>%
   filter(barcode_number==bcnb) %>%
   filter(rep_number==repnb))$nb_comp_combinations

barcodeFreq %>% filter(chemistry == chem) %>% 
  filter(mplex_level==mpl) %>%
  filter(barcode_number==bcnb) %>%
  filter(rep_number==repnb) %>%
  mutate(channel=paste0(chemistry, "-channel"),
         mplex_level=paste("mutiplex level",mplex_level)) %>%
  ggplot(aes(x=barcodeID,y=occurrence, fill=mplex_level))+
  geom_histogram(stat = "identity", fill= "darkgrey")+
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
  facet_grid(mplex_level~channel) +
  xlab("BarcodeID")+
  ylab("Barcode occurences")+
ggtitle(paste("Barcode occurences among",nb_comp_combinations,"compatible barcode combinations (",chem,"- channel )"))
```



# Simulations relative to Step2 of the workflow

* Step2: optimize the set of compatible barcodes to minimize redundancy between barcodes

The goal is to estimate the probability to get an optimal solution (maximum entropy) and to test how the optimizer improves the solution compared with a random pick.
To estimate the probability to get an optimal with the greedy-descent algorithm, we perform 100 simulations for a fixed size of a randomly generated subset of compatible combinations.
We also test how the size of the subset of compatible combinations influences the probability to obtain an optimal solution. This allows us to find a good compromise between computation time and accuracy.
In practice the running time of the greedy-descent algorithm gets very long for large initial sets of compatible combinations. So, we randomly generate a subset from the entire set of compatible combinations and run the simulations to estimate the probability q to get an optimal solution for each trial. Based on this result, we devised an optimizer function that performs N trials of the greedy-descent algorithm from the same subset of compatible combinations. The probability P of getting an optimal solution after $N$ iterations reads $P_{N} = 1-(1-P_{1})^N$. For example, if we want to find an optimal solution at least 90% of cases $(P_{N} = 0.9)$, we need a number of iterations $N >= log(1-P_{N})/log(1-P_{1})$.  



* We therefore run two series of simulations:

    + Step2a: find the probability q of to get an optimal combination for each trial given the subset size, estimate N for P = 0.90, and refine computation time.
    + Step2b: check the efficacy of the optimizer function with a fixed set of parameters p, N and subset size.


## Step2a: set parameters for the simulations

From simulations in step1, we know that at least 1000 compatible barcode combinations can be obtained for mplex_level >= 4 , barcode set >= 18, regardless the chemistry.
We define a set of parameters that are relevant in the context of RNAseq:

* Chemistry: 4 (4-channel chemistry)
* Barcode-set size: 18
* Multiplex level: 4
* Number of libraries: 16 (therefore 4 lanes will be used in a flow cell)

```{r echo = FALSE}
R=100
L = c(12,18,24,30)
N = 3:5
C = c(2,4)
thrs_size_comb=c(seq(10,50,5),seq(60,100, 10))
max_iteration = 0
nb_lane=c(4,6,8)
algorithm= c("greedy_exchange", "greedy_descent")

R=20
L = c(18)
N = 4
C = c(4)
thrs_size_comb=c(130)
max_iteration = 0
nb_lane=c(4)
algorithm= c("greedy_exchange", "greedy_descent")


print("CONDITIONS:")
print("Barcode set size:")
N
print("Multiplex levels:")
L 
print("Chemistry:")
C
print("Number of simulations per greedy-descent search:")
R
print("Size of compatible combinations set used for greedy-descent:")
thrs_size_comb

print("Number of iterations for the greedy-descent:")
max_iteration

print("Number of lanes:")
nb_lane

print("Total number of combinations:")
choose(L,N)

print("Optimizer algorithms")
algorithm

print(paste("Number of conditions:",R*length(L)*length(N)*length(C)*length(thrs_size_comb)*length(nb_lane)))

```

## Run simulations for step2a


```{r echo = FALSE, cache=F}

# Initialize output file1 (barcode occurrence from random pic)
write.table(data.frame(barcodeID=character(0), occurrence=integer(0), rep_number=integer(0), thrs_size_comb=integer(0), barcode_number=integer(0), chemistry=integer(0), nb_lane=integer(0), mplex_level=integer(0), algorithm=character(0)),
            outputfile1 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Initialize output file2 (barcode occurrence from optimized set)
write.table(data.frame(barcodeID=character(0), occurrence=integer(0), rep_number=integer(0), thrs_size_comb=integer(0), barcode_number=integer(0), chemistry=integer(0), nb_lane=integer(0), mplex_level=integer(0), algorithm=character(0)),
            outputfile2 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Initialize output file3 (calcul of proba to get an optimal solution)
write.table(data.frame(time=numeric(0), nb_comp_combinations=integer(0), rep_number=integer(0), barcode_number=integer(0), thrs_size_comb=integer(0), S_max=numeric(0), S_init=numeric(0), S_random=numeric(0), S_opt=numeric(0), chemistry=integer(0), nb_lane=integer(0), mplex_level=integer(0), algorithm=character(0)),
            outputfile3 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Detect CPU number
nb_cpu=parallel::detectCores()

if (T) {
  system.time({
    for (i in L) {
      # Generate a large set of compatible combinations
      index <- dplyr::sample_n(DNABarcodeCompatibility::IlluminaIndexes, nrow(DNABarcodeCompatibility::IlluminaIndexes), replace = FALSE)
      for (j in N) {
        for (k in C) {
          # Initialize input file with a matrix of all combinations
          combination_m <- DNABarcodeCompatibility::get_all_combinations(index_df = index[1:i,], mplex_level = j, chemistry = k)
          
          inc=0
          while (nrow(combination_m) < max(nb_lane) && inc<10) {
            print("nrow(combination_m) might be too small")
            print("other trial...")
            index <- dplyr::sample_n(DNABarcodeCompatibility::IlluminaIndexes, nrow(DNABarcodeCompatibility::IlluminaIndexes), replace = FALSE)
            combination_m <- DNABarcodeCompatibility::get_all_combinations(index_df = index[1:i,], mplex_level = j, chemistry = k)
            inc=inc+1
            print(inc)
          }
          if (nrow(combination_m)<max(nb_lane)) {warning("nrow(combination_m) might be too small")}
          
          inputfile <- tempfile()
          save(combination_m, file=inputfile)
          # save(combination_m, file="combination_m_4ch")
          
          # Run simulation using GNU parallel (Windows users need cygwin + Gnu parallel; MacOs: brew install parallel; Linux: apt-get install parallel)
          system(paste0("parallel -j",nb_cpu," Rscript ",SCRIPT_DIR,"sim_optimize_combinations.R {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11} {12} ::: ",paste(1:R, collapse=" ")," ::: ",paste(thrs_size_comb, collapse=" ")," ::: " , paste(max_iteration, collapse=" "), " ::: ",paste(inputfile, collapse=""), " ::: ", paste(nb_lane, collapse=" "), " ::: ", paste(i, collapse=""), " ::: ", paste(k, collapse=""), " ::: ", paste(outputfile1, collapse=""), " ::: ", paste(outputfile2, collapse=""), " ::: ", paste(outputfile3, collapse=""), " ::: ", paste(j, collapse=""), " ::: ", paste(algorithm, collapse=" ")))
          
        }
      }
    }
    
    sim1_barcodeStat_random <- read.table(file=outputfile1, header = T, sep = " ", stringsAsFactors = FALSE)
    save(sim1_barcodeStat_random, file = paste0(SCRIPT_DIR,"XXXsim1_barcodeStat_random"))
    
    sim1_barcodeStat_opt <- read.table(file=outputfile2, header = T, sep = " ", stringsAsFactors = FALSE)
    save(sim1_barcodeStat_opt, file = paste0(SCRIPT_DIR,"XXXsim1_barcodeStat_opt"))
    
    sim1_probaSmax <- read.table(file=outputfile3, header = T, sep = " ", stringsAsFactors = FALSE)
    save(sim1_probaSmax, file = paste0(SCRIPT_DIR,"XXXsim1_probaSmax"))
  })
}


# Import results
sim1_barcodeStat_random <- local(get(load(paste0(SCRIPT_DIR,"sim1_barcodeStat_random"))))
sim1_barcodeStat_opt <- local(get(load(paste0(SCRIPT_DIR,"sim1_barcodeStat_opt"))))
sim1_probaSmax <- local(get(load(paste0(SCRIPT_DIR,"sim1_probaSmax"))))


```

### Statistic summary

```{r echo = FALSE, fig.width=11, eval=F}
for (i in thrs_size_comb){
  # for (j in barcode_number) {
    stat <- sim1_probaSmax %>% filter(thrs_size_comb==i) %>%
      select(-c(rep_number,barcode_number,thrs_size_comb,chemistry,nb_lane, mplex_level)) %>%
      summary()
    print(i)
    print(stat)
  # }
}
```

### Probability to get an optimal set of barcode combinations (entropy max) for a single greedy-descent run

```{r echo = FALSE,  warning=FALSE, message=F, fig.width=11}

sim1_probaSmax %>% group_by(chemistry, barcode_number, mplex_level, nb_lane) %>%
  filter(thrs_size_comb<nb_comp_combinations) %>%
  mutate(isSmax=ifelse(abs(S_opt-S_max)<10^(-10), T, F)) %>%
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_comp_combinations=nb_comp_combinations[1], S_max=S_max[1], ProbaOfSmax=sum(isSmax)/length(rep_number)) %>%
  ungroup() %>% 
  mutate(mplex_level=as.factor(mplex_level),
         chemistry=paste0(chemistry,"-channel"),
         nb_lane=paste(nb_lane,"lanes"),
         barcode_number=paste("set of",barcode_number,"barcodes")) %>%
ggplot(aes( x = thrs_size_comb, y = ProbaOfSmax, color=mplex_level)) +
  geom_point() +
  geom_smooth(se = F) +
  scale_x_continuous(breaks=seq(0, 300, 50)) +
  scale_y_continuous(breaks=seq(0, 1, 0.2), limit=c(0, 1.1)) +
  facet_grid(chemistry+nb_lane~barcode_number) +
  
  ggtitle(paste("Proba to get exactly Smax after a single run: calculated from", R, "runs")) +
  xlab("Size of the initial set of compatible barcodes") +
  ylab("Probability to get an optimal combination")

```

### Probability to get the best optimized set of barcode combinations for a single greedy-descent run

```{r echo = FALSE,  warning=FALSE, message=F, fig.width=11}

sim1_probaSmax %>% group_by(chemistry, barcode_number, mplex_level, nb_lane) %>%
  filter(thrs_size_comb<nb_comp_combinations) %>%
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  mutate(S_sup=max(S_opt),
         isSsup=ifelse(abs(S_opt-S_sup)<10^(-10), T, F)) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_comp_combinations=nb_comp_combinations[1], S_sup=S_sup[1], ProbaOfSsup=sum(isSsup)/length(rep_number)) %>%
  ungroup() %>% 
  mutate(mplex_level=as.factor(mplex_level),
         chemistry=paste0(chemistry,"-channel"),
         nb_lane=paste(nb_lane,"lanes"),
         barcode_number=paste("set of",barcode_number,"barcodes")) %>%
ggplot(aes( x = thrs_size_comb, y = ProbaOfSsup, color=mplex_level)) +
  geom_point() +
  geom_smooth(se = F) +
  scale_x_continuous(breaks=seq(0, 300, 50)) +
  scale_y_continuous(breaks=seq(0, 1, 0.2), limit=c(0, 1.1)) +
  facet_grid(chemistry+nb_lane~barcode_number) +
  
  ggtitle(paste("Proba to get the best optimized set after a single run: calculated from", R, "runs")) +
  xlab("Size of the initial set of compatible barcodes") +
  ylab("Probability to get an optimal combination")

```

### Execution time of a single greedy-descent run for different sizes of compatible combination subsets

```{r echo = FALSE,  warning=FALSE, message=F, fig.width=11}

sim1_probaSmax %>% group_by(chemistry, barcode_number, mplex_level, nb_lane) %>%
  filter(thrs_size_comb<nb_comp_combinations) %>%
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_comp_combinations=nb_comp_combinations[1]) %>%
  ungroup() %>% 
  mutate(mplex_level=as.factor(mplex_level),
         chemistry=paste0(chemistry,"-channel"),
         nb_lane=paste(nb_lane,"lanes"),
          barcode_number=paste("set of",barcode_number,"barcodes")) %>%
ggplot(aes( x = thrs_size_comb, y = time.avg, color=mplex_level)) +
  geom_point() + geom_line() + geom_smooth() +
  geom_errorbar(aes(ymin=(time.avg-time.sd), ymax=(time.avg+time.sd)),
                color="black") +
  # geom_smooth(method = "lm", se = FALSE)+
  scale_x_continuous(breaks=c(10, 50, 100, 200, 300)) +
  scale_y_continuous(breaks = c(1, 15,30,90,200, 250))+
  geom_hline(yintercept=30, linetype="dashed", color = "red")+
  geom_hline(yintercept=15, linetype="dashed", color = "red")+
  geom_hline(yintercept=1, linetype="dashed", color = "red")+
  facet_grid(chemistry+nb_lane~barcode_number) +
  ggtitle(paste("Execution time of a single greedy-descent: averaged for", R, "runs")) +
  xlab("Size of the initial subset of compatible barcodes") +
  ylab("Execution time [s]")

```

```{r echo = FALSE,  warning=FALSE, message=F, fig.width=11}

sim1_probaSmax %>% group_by(chemistry, barcode_number, mplex_level, nb_lane) %>%
  filter(thrs_size_comb<nb_comp_combinations) %>%
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_comp_combinations=nb_comp_combinations[1]) %>%
  ungroup() %>% 
  mutate(mplex_level=as.factor(mplex_level),
         chemistry=paste0(chemistry,"-channel"),
         nb_lane=paste(nb_lane,"lanes"),
          barcode_number=paste("set of",barcode_number,"barcodes")) %>%
ggplot(aes( x = thrs_size_comb, y = time.avg, color=mplex_level)) +
  geom_point() + #geom_line() + geom_smooth() +
  geom_errorbar(aes(ymin=(time.avg-time.sd), ymax=(time.avg+time.sd)),
                color="black") +
  geom_smooth(method = "lm", se = T)+
  scale_x_log10(breaks=c(10, 50, 80, 100, 200, 300)) +
  scale_y_log10(breaks = c(1, 5,15,30,90,200, 250))+
  geom_hline(yintercept=30, linetype="dashed", color = "red")+
  geom_hline(yintercept=15, linetype="dashed", color = "red")+
  geom_hline(yintercept=1, linetype="dashed", color = "red")+
  facet_grid(chemistry+nb_lane~barcode_number) +
  ggtitle(paste("Execution time of a single greedy-descent: averaged for", R, "runs")) +
  xlab("Size of the initial subset of compatible barcodes") +
  ylab("Execution time [s]")

```


### Estimation of the maximum execution time of N iterations of the greedy-descent to obtain the max entropy in 90% of cases


 The probability P of getting an optimal solution reads $P = 1-(1-q)^N$. For example, if we want to find an optimal solution for 90% of cases (P = 0.90), $N = log(0.1)/log(1-q)$.
 

```{r echo = FALSE,  warning=FALSE, fig.width=11}
# for 90% of cases
P=0.90

sim1_probaSmax %>% 
  group_by(chemistry, barcode_number, mplex_level, nb_lane) %>%
  filter(thrs_size_comb<nb_comp_combinations) %>% 
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  mutate(S_sup=max(S_opt),
         isSsup=ifelse(abs(S_opt-S_sup)<10^(-10), T, F)) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_comp_combinations=nb_comp_combinations[1], S_sup=S_sup[1], ProbaOfSsup=sum(isSsup)/length(rep_number)) %>%
  ungroup() %>%
  mutate(mplex_level=as.factor(mplex_level),
         chemistry=paste0(chemistry,"-channel"),
         nb_lane=paste(nb_lane,"lanes"),
         barcode_number=paste("set of",barcode_number,"barcodes")) %>%
  mutate(N=ceiling(log(1-P)/log(1-ProbaOfSsup)),
         exec_time=(N+1)*time.avg) %>%
  ggplot(aes(x = thrs_size_comb, y = exec_time, color=N, shape=mplex_level)) +
  geom_point(size = 2) +
  scale_colour_gradientn(colours = rainbow(5)) +
  scale_x_log10(breaks=c(10, 15, 20, 40,60, 80,120, 200, 300)) +
  scale_y_log10(breaks = c(1, 2,5, 10,30,90,200,1000,5000,10000, 20000)) +
  geom_hline(yintercept=30, linetype="dashed", color = "black")+
  geom_hline(yintercept=10, linetype="dashed", color = "black")+
  geom_hline(yintercept=2, linetype="dashed", color = "black")+
  facet_grid(chemistry+nb_lane~barcode_number) +
  ggtitle(paste("Estimated execution time to find an optimal solution in",P*100,"% of cases")) +
  xlab("Size of the initial subset of compatible barcodes") +
  ylab("Maximum execution time [s]")


```

### Estimation of the maximum execution time of N iterations of the greedy-descent to obtain the max entropy in 99% of cases


 The probability P of getting an optimal solution reads $P = 1-(1-q)^N$. For example, if we want to find an optimal solution for 99% of cases (P = 0.99), $N = log(0.01)/log(1-q)$.
 

```{r echo = FALSE,  warning=FALSE, fig.width=11}
# for 90% of cases
P=0.99

sim1_probaSmax %>% 
  group_by(chemistry, barcode_number, mplex_level, nb_lane) %>%
  filter(thrs_size_comb<nb_comp_combinations) %>% 
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  mutate(S_sup=max(S_opt),
         isSsup=ifelse(abs(S_opt-S_sup)<10^(-10), T, F)) %>%
  summarise(time.avg=mean(time), time.sd=sd(time), nb_comp_combinations=nb_comp_combinations[1], S_sup=S_sup[1], ProbaOfSsup=sum(isSsup)/length(rep_number)) %>%
  ungroup() %>%
  mutate(mplex_level=as.factor(mplex_level),
         chemistry=paste0(chemistry,"-channel"),
         nb_lane=paste(nb_lane,"lanes"),
         barcode_number=paste("set of",barcode_number,"barcodes")) %>%
  mutate(N=ceiling(log(1-P)/log(1-ProbaOfSsup)),
         exec_time=(N+1)*time.avg) %>%
  ggplot(aes(x = thrs_size_comb, y = exec_time, color=N, shape=mplex_level)) +
  geom_point(size = 2) +
  scale_colour_gradientn(colours = rainbow(5)) +
  scale_x_log10(breaks=c(10, 15, 20, 40,60, 80,120, 200, 300)) +
  scale_y_log10(breaks = c(1, 2,5, 10,30,90,200,1000,5000,10000, 20000)) +
  geom_hline(yintercept=30, linetype="dashed", color = "black")+
  geom_hline(yintercept=10, linetype="dashed", color = "black")+
  geom_hline(yintercept=2, linetype="dashed", color = "black")+
  facet_grid(chemistry+nb_lane~barcode_number) +
  ggtitle(paste("Estimated execution time to find an optimal solution in",P*100,"% of cases")) +
  xlab("Size of the initial subset of compatible barcodes") +
  ylab("Maximum execution time [s]")


```


### Distributions of entropy values without (S_random) and with (S_opt) optimization

To visualize the efficacy of the greedy-descent algorithm, we compare the distribution of entropy values obtained from randomly generated sets of compatible barcodes with the distribution of entropy values obtained from optimized (by greedy-descent) sets of compatible barcodes. The graphs below show that the greedy-descent algorithm dramatically reduces the barcode redanduncy by favoring sets of compatible barcode combinations with a higher entropy.

* For N randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, fig.height=11}
sim1_probaSmax %>% group_by(chemistry, barcode_number, mplex_level, nb_lane) %>%
  filter(thrs_size_comb<nb_comp_combinations) %>% ungroup() %>%
  # filter(thrs_size_comb == 60) %>%
  mutate(isSmax=ifelse(S_opt==S_max, T, F),
         S_opt=round(S_opt, 3),
         S_random=round(S_random, 3), 
         mplex_level=as.factor(mplex_level),
         chemistry=paste0(chemistry,"-channel"),
         nb_lane=paste(nb_lane,"lanes"),
         barcode_number=paste("set of",barcode_number,"barcodes")) -> dat

dat %>%
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  do ({
    chunk <- .
    with(chunk, as.data.frame(table(S=S_random))) %>% 
      mutate(Freq=Freq/sum(Freq),
             S_max=chunk$S_max[1],
             dataset="S_random")
  }) %>% ungroup() %>% mutate(S=as.double(S)) -> S_random_freq 


dat %>%
  group_by(chemistry, barcode_number, mplex_level, nb_lane, thrs_size_comb) %>%
  do ({
    chunk <- .
    with(chunk, as.data.frame(table(S=S_opt))) %>% 
      mutate( Freq=Freq/sum(Freq), 
              S_max=chunk$S_max[1], 
              dataset="S_opt") 
  }) %>% ungroup() %>% mutate(S=as.double(S)) -> S_opt_freq


Sdat=bind_rows(S_random_freq, S_opt_freq)

k=1
gg <- list()

for (i in unique(Sdat$thrs_size_comb)){
  
  Sdat %>% filter(thrs_size_comb == i) %>%
    # mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
    ggplot(aes(x = S)) +
    geom_histogram(aes(y=0.05*..density.., fill=dataset), position='identity', alpha=0.7, binwidth=0.05, boundary=0.05) +
    geom_vline(aes(xintercept = S_max, color="S_max"), linetype="dashed") +
    scale_x_continuous(breaks=round(seq(min(dat$S_random), max(dat$S_opt), (max(dat$S_opt)-min(dat$S_random))/5),2)) +
    # scale_x_discrete(breaks=sort(sample(dat$S_random,5)))+
    theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
    facet_grid(chemistry+mplex_level+nb_lane~barcode_number) +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
    xlab("Entropy values") +
    ylab("Frequency") +
    ggtitle(paste("Distributions of entropy values for (",i ,"combs;", R, "runs)")) -> gg[[k]]
  k=k+1
}
gg

```

* For 70 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (70 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
    filter(thrs_size_comb == 70) -> dat
  
  dat %>%
    mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
    ggplot(aes(y = (..count..)/sum(..count..))) +
    geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
    facet_wrap(~thrs_size_comb) +
    xlab("Entropy values") +
    ylab("Frequency") +
    ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}
```

* For 80 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (80 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
    filter(thrs_size_comb == 80) -> dat
  
  dat %>%
    mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
    ggplot(aes(y = (..count..)/sum(..count..))) +
    geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
    facet_wrap(~thrs_size_comb) +
    xlab("Entropy values") +
    ylab("Frequency") +
    ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}
```

* For 90 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (90 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
    filter(thrs_size_comb == 90) -> dat
  
  dat %>%
    mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
    ggplot(aes(y = (..count..)/sum(..count..))) +
    geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
    facet_wrap(~thrs_size_comb) +
    xlab("Entropy values") +
    ylab("Frequency") +
    ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}
```

* For 100 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (100 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
    filter(thrs_size_comb == 100) -> dat
  
  dat %>%
    mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
    ggplot(aes(y = (..count..)/sum(..count..))) +
    geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
    facet_wrap(~thrs_size_comb) +
    xlab("Entropy values") +
    ylab("Frequency") +
    ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}
```

* For 120 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (120 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
  filter(thrs_size_comb == 120) -> dat
  
  dat %>%
  mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
ggplot(aes(y = (..count..)/sum(..count..))) +
  geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
  facet_wrap(~thrs_size_comb) +
  xlab("Entropy values") +
  ylab("Frequency") +
  ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}

```

* For 160 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (160 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
  filter(thrs_size_comb == 160) -> dat
  
  dat %>%
  mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
ggplot(aes(y = (..count..)/sum(..count..))) +
  geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
  facet_wrap(~thrs_size_comb) +
  xlab("Entropy values") +
  ylab("Frequency") +
  ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}

```

* For 320 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (320 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
  filter(thrs_size_comb == 320) -> dat
  
  dat %>%
  mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
ggplot(aes(y = (..count..)/sum(..count..))) +
 geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
  facet_wrap(~thrs_size_comb) +
  xlab("Entropy values") +
  ylab("Frequency") +
  ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}

```


* For 640 randomly picked up compatible combinations
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11, eval=F}
if (640 %in% sim1_probaSmax$thrs_size_comb) {
  sim1_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
    filter(thrs_size_comb == 640) -> dat
  
  dat %>%
    mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
    ggplot(aes(y = (..count..)/sum(..count..))) +
   geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
    facet_wrap(~thrs_size_comb) +
    xlab("Entropy values") +
    ylab("Frequency") +
    ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}
```


## Step2b: set parameters for the simulations

* Chemistry: 4 (4-channel chemistry)
* Barcode-set size: 18
* Multiplex level: 4
* Number of libraries: 16 (therefore 4 lanes will be used in a flow cells)
* Subset size: 80
* Iterations: 14

```{r echo = FALSE}
R=100
L = c(18)
N = 4
C = c(4)
thrs_size_comb=c(80)
max_iteration = 14
nb_lane=c(4)

# R=1
# L = c(18)
# N = 4
# C = c(4)
# thrs_size_comb=c(80)
# max_iteration = 14
# nb_lane=c(4)


print("CONDITIONS:")
print("Barcode set size:")
N
print("Multiplex levels:")
L 
print("Chemistry:")
C
print("Number of simulations per greedy-descent search:")
R
print("Size of compatible combinations set used for greedy-descent:")
thrs_size_comb

print("Number of iterations for the greedy-descent:")
max_iteration

print("Number of lanes:")
nb_lane

print("Total number of combinations:")
choose(L,N)

print(paste("Number of conditions:",R*length(L)*length(N)*length(C)*length(thrs_size_comb)*length(nb_lane)))

```

## Run simulations for step2b

```{r echo = FALSE, cache=T}

# Reuse the dataset generated in the first series of simulations
combination_m_4ch <- local(get(load(paste0(SCRIPT_DIR,"combination_m_4ch"))))

inputfile <- tempfile()
save(combination_m_4ch, file=inputfile)

# Initialize output file1 (barcode occurrence from random pic)
write.table(data.frame(barcodeID=character(0), occurrence=integer(0), rep_number=integer(0), thrs_size_comb=integer(0), barcode_number=integer(0), chemistry=integer(0), nb_lane=integer(0), mplex_level=integer(0)),
            outputfile1 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Initialize output file2 (barcode occurrence from optimized set)
write.table(data.frame(barcodeID=character(0), occurrence=integer(0), rep_number=integer(0), thrs_size_comb=integer(0), barcode_number=integer(0), chemistry=integer(0), nb_lane=integer(0), mplex_level=integer(0)),
            outputfile2 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Initialize output file3 (calcul of proba to get an optimal solution)
write.table(data.frame(time=numeric(0), nb_comp_combinations=integer(0), rep_number=integer(0), barcode_number=integer(0), thrs_size_comb=integer(0), S_max=numeric(0), S_init=numeric(0), S_random=numeric(0), S_opt=numeric(0), chemistry=integer(0), nb_lane=integer(0), mplex_level=integer(0)),
            outputfile3 <- tempfile(), row.names = FALSE, col.names = T, quote=FALSE)

# Detect CPU number
nb_cpu=parallel::detectCores()

if (F) {
  # Run simulation using GNU parallel (Windows users need cygwin + Gnu parallel; MacOs: brew install parallel; Linux: apt-get install parallel)
  system.time({
  system(paste0("parallel -j",nb_cpu," Rscript ",SCRIPT_DIR,"sim_optimize_combinations.R {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11} ::: ",paste(1:R, collapse=" ")," ::: ",paste(thrs_size_comb, collapse=" ")," ::: " , paste(max_iteration, collapse=" "), " ::: ",paste(inputfile, collapse=""), " ::: ", paste(nb_lane, collapse=" "), " ::: ", paste(18, collapse=" "), " ::: ", paste(4, collapse=" "), " ::: ", paste(outputfile1, collapse=""), " ::: ", paste(outputfile2, collapse=""), " ::: ", paste(outputfile3, collapse=""), " ::: ", paste(4, collapse=" ")))
  })
  
  sime2_barcodeStat_random <- read.table(file=outputfile1, header = T, sep = " ", stringsAsFactors = FALSE)
  save(sime2_barcodeStat_random, file = paste0(SCRIPT_DIR,"sim2_barcodeStat_random"))
  
  sim2_barcodeStat_opt <- read.table(file=outputfile2, header = T, sep = " ", stringsAsFactors = FALSE)
  save(sim2_barcodeStat_opt, file = paste0(SCRIPT_DIR,"sim2_barcodeStat_opt"))
  
  sim2_probaSmax <- read.table(file=outputfile3, header = T, sep = " ", stringsAsFactors = FALSE)
  save(sim2_probaSmax, file = paste0(SCRIPT_DIR,"sim2_probaSmax"))
}


if (F) {
  system.time({
    for (i in L) {
      for (j in N) {
        for (k in C) {
          # Generate a large set of compatible combinations
          index <- dplyr::sample_n(DNABarcodeCompatibility::IlluminaIndexes, nrow(DNABarcodeCompatibility::IlluminaIndexes), replace = FALSE)
          
          # Initialize input file with a matrix of all combinations
          combination_m <- DNABarcodeCompatibility::get_all_combinations(index_df = index[1:i,], mplex_level = j, chemistry = k)
          
          # Run simulation using GNU parallel (Windows users need cygwin + Gnu parallel; MacOs: brew install parallel; Linux: apt-get install parallel)
          system(paste0("parallel -j",nb_cpu," Rscript ",SCRIPT_DIR,"sim_optimize_combinations.R {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11} ::: ",paste(1:R, collapse=" ")," ::: ",paste(thrs_size_comb, collapse=" ")," ::: " , paste(max_iteration, collapse=" "), " ::: ",paste(inputfile, collapse=""), " ::: ", paste(nb_lane, collapse=" "), " ::: ", paste(i, collapse=""), " ::: ", paste(k, collapse=""), " ::: ", paste(outputfile1, collapse=""), " ::: ", paste(outputfile2, collapse=""), " ::: ", paste(outputfile3, collapse=""), " ::: ", paste(j, collapse="")))
        }
      }
    }
    sime2_barcodeStat_random <- read.table(file=outputfile1, header = T, sep = " ", stringsAsFactors = FALSE)
    save(sime2_barcodeStat_random, file = paste0(SCRIPT_DIR,"sim2_barcodeStat_random"))
    
    sim2_barcodeStat_opt <- read.table(file=outputfile2, header = T, sep = " ", stringsAsFactors = FALSE)
    save(sim2_barcodeStat_opt, file = paste0(SCRIPT_DIR,"sim2_barcodeStat_opt"))
    
    sim2_probaSmax <- read.table(file=outputfile3, header = T, sep = " ", stringsAsFactors = FALSE)
    save(sim2_probaSmax, file = paste0(SCRIPT_DIR,"sim2_probaSmax"))
  }
  )
}       

        
# Import results
sim2_barcodeStat_random <- local(get(load(paste0(SCRIPT_DIR,"sim2_barcodeStat_random"))))
sim2_barcodeStat_opt <- local(get(load(paste0(SCRIPT_DIR,"sim2_barcodeStat_opt"))))
sim2_probaSmax <- local(get(load(paste0(SCRIPT_DIR,"sim2_probaSmax"))))

```

###  Distributions of entropy values without (S_random) and with (S_opt) the optimizer

* For randomly picked up 80 compatible combinations and up to 14 iterations of the greedy descent
```{r echo = FALSE,  warning=FALSE, message=FALSE, fig.width=11}
if (80 %in% sim2_probaSmax$thrs_size_comb) {
  sim2_probaSmax %>% mutate(isSmax=ifelse(S_opt==S_max, T, F)) %>%
    filter(thrs_size_comb == 80)-> dat
  
  dat %>%
    mutate(thrs_size_comb=as.factor(thrs_size_comb)) %>%
    ggplot(aes(y = (..count..)/sum(..count..))) +
    geom_histogram(aes(x = S_opt,fill="S_opt"), alpha=0.5, center=dat$S_max[1],  binwidth = 0.01) +
    geom_histogram(aes(x = S_random,fill="S_random"), alpha=0.5, center=dat$S_max[1], binwidth = 0.01) +
    # geom_density(aes(x = S_opt,fill="S_opt"), alpha=0.5, color= "black", adjust=0.1) +
    # geom_density(aes(x = S_random,fill="S_random"), alpha=0.5, color= "black", adjust=0.1) +
    geom_vline(aes(xintercept = S_max[1], color="S_max"), linetype="dashed") +
    scale_fill_manual("Entropy",
                      breaks = c("S_opt", "S_random"),
                      values = c("green", "red")) +
    scale_color_manual("",
                       breaks = c("S_max", "S_opt", "S_random"),
                       values = c("blue", "green", "red")) +
    scale_y_continuous(breaks = c(seq(0,1,0.25),0.9, 0.95))+
    facet_wrap(~thrs_size_comb) +
    xlab("Entropy values") +
    ylab("Frequency") +
    ggtitle(paste("Frequency distributions of entropy values for", R, "runs")) 
}
```

### Comparison of barcode distributions between a randomly generated set and an optimized set of compatible combinations

In this simulation, we have 16 libraries (multiplex level = 4; number of lanes = 4). To visualize the efficacy of the optimizer, we show the barcode distrubution before and after the optimization.

* Set of compatible combinations that was randomly selected

```{r echo = FALSE, warning=FALSE, fig.width=11}
chem=4
mpl=4
bcnb=18
repnb=26

S_random <- (sim2_probaSmax %>% filter(chemistry == chem) %>% 
   filter(mplex_level==mpl) %>%
   filter(barcode_number==bcnb) %>%
   filter(rep_number==repnb))$S_random

S_max <- (sim2_probaSmax %>% filter(chemistry == chem) %>% 
   filter(mplex_level==mpl) %>%
   filter(barcode_number==bcnb) %>%
   filter(rep_number==repnb))$S_max

sim2_barcodeStat_random %>% filter(chemistry == chem) %>% 
  filter(mplex_level==mpl) %>%
  filter(barcode_number==bcnb) %>%
  filter(rep_number==repnb) %>%
  mutate(channel=paste0(chemistry, "-channel"),
         mplex_level=paste("mutiplex level",mplex_level)) %>%
  ggplot(aes(x=barcodeID,y=occurrence, fill=mplex_level))+
  geom_histogram(stat = "identity", fill= "darkgrey")+
  scale_y_continuous(breaks = 1:4, limits = c(0,4))+
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
  facet_grid(mplex_level~channel) +
  xlab("BarcodeID")+
  ylab("Barcode occurrences")+
ggtitle(paste0("Barcode occurences from a random set of compatible combinations (S_random=",round(S_random,2),"; S_max=",round(S_max,2),")"))

```


* Set of compatible barcodes that was optimized with the optimizer

```{r echo = FALSE, warning=FALSE, fig.width=11}
chem=4
mpl=4
bcnb=18
repnb=26

S_opt <- (sim2_probaSmax %>% filter(chemistry == chem) %>% 
   filter(mplex_level==mpl) %>%
   filter(barcode_number==bcnb) %>%
   filter(rep_number==repnb))$S_opt

S_max <- (sim2_probaSmax %>% filter(chemistry == chem) %>% 
   filter(mplex_level==mpl) %>%
   filter(barcode_number==bcnb) %>%
   filter(rep_number==repnb))$S_max

sim2_barcodeStat_opt %>% filter(chemistry == chem) %>% 
  filter(mplex_level==mpl) %>%
  filter(barcode_number==bcnb) %>%
  filter(rep_number==repnb) %>%
  mutate(channel=paste0(chemistry, "-channel"),
         mplex_level=paste("mutiplex level",mplex_level)) %>%
  ggplot(aes(x=barcodeID,y=occurrence, fill=mplex_level))+
  geom_histogram(stat = "identity", fill= "darkgrey")+
  scale_y_continuous(breaks = 1:4, limits = c(0,4))+
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=1))+
  facet_grid(mplex_level~channel) +
  xlab("BarcodeID") +
  ylab("Barcode occurrences") +
ggtitle(paste0("Barcode occurences from a random set of compatible combinations (S_opt=",round(S_opt,2),"; S_max=",round(S_max,2),")"))
```
